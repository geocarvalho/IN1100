{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Árvores de decisão\n",
    "\n",
    "* Método para inferência indutiva;\n",
    "* Auxilia a predizer a classe de um objeto em estudo com base em treinamento prévio;\n",
    "* Uma árvore representa uma função discreta para aproximar/representar os dados de treinamento;\n",
    "* Árvores de decisão classificam instâncias ordenando-as da raíz para algum nó folha;\n",
    "> Cada nó da árvore representa um atributo.\n",
    "* [Uma Introducao Visual ao Aprendizado de Maquina - usar exemplo com árvode de decisão](http://www.r2d3.us/uma-introducao-visual-ao-aprendizado-de-maquina-1/)\n",
    "\n",
    "### Exemplo: Jogar tênis\n",
    "* Classifica se um determinado dia é adrequado ou não para jogar tênis;\n",
    "![jogar tenis](jogar_tenis.png)\n",
    "\n",
    "* Por exemplo:\n",
    "> 1. Tendo a instância: (Panorama=Ensolarado) e (Temperatura=Quente) e (Umidade=Alta)\n",
    "> 2. Saída: **Não**\n",
    "\n",
    "* Pode se monta uma expressão para verificar quando é possível jogar tênis:\n",
    "> (Panorama=Ensolarado) e (Umidade=Normal) ou (Panorama=Nublado) ou (Panorama=Chuvoso) e (Vento=Fraco)\n",
    "\n",
    "* Portanto podemos gerar uma árvore de decisão e depois **obter regras** que nos auxiliam a classificar instâncias nunca vistas.\n",
    "\n",
    "## Regiões de decisão\n",
    "\n",
    "![regioes de decisao](regioes_de_decisao.png)\n",
    "\n",
    "### Tipos de problemas para aplicação\n",
    "\n",
    "* Instâncias são representadas por **pares atributo-valor**: Há um conjunto fixo de atributos (ex.: Umidade) e seus valores (ex.: Alta, Nomal). Situação ideal é quando cada atributo pode assumir **poucos valores**, no entanto, as árvores de decisão também podem trabalhar com valores reais.\n",
    "\n",
    "* A função a ser aproximada tem **valores discretos**: No exemplo a função deve produzir **sim** ou **não**. Pode-se facilmente estendê-las para produzir mais de dois valores de saída. Tornam-se mais complexas e menos utilizadas abordagens que buscam produzir valores reais como saída.\n",
    "\n",
    "* Aplicações comuns: Diagnóstico de pacientes, problemas em equipamentos mecânicos e elétricos, análise de crédito.\n",
    "\n",
    "### Tipos de algoritmo\n",
    "\n",
    "* Mais conhecidos: ID3 (Quinlan, 1986) e C4.5 (Quinlan, 1993)\n",
    "\n",
    "#### Algoritmo ID3\n",
    "\n",
    "* Considere um conjunto de dados para treinamento;\n",
    "* Ele constrói a árvore em uma abordagem ***top-down*** considerando a questão: **\"Qual atributo é o mais importante e, portanto, deve ser colocado na raíz da árvore?\"**;\n",
    "* Para isso **cada atributo é testado** e sua capacidade para se tornar nó raíz avaliada;\n",
    "* Cria-se tantos **nós filhos da raíz** quantos valores possíveis esse atributo puder assumir (caso discreto);\n",
    "* **Repete-se o processo** para cada nó filho da raíz e assim sucessivamente.\n",
    "* Como avaliar qual o atributo é mais adequado? Por **entropia**\n",
    "\n",
    "#### Entropia\n",
    "\n",
    "* Propriedade da termodinâmica usada para determinar a quantidade de energia útil de um sistema qualquer;\n",
    "* Gibbs afirmou que a melhor interpretação para entropia na mecânica estatística é como uma **medida de incerteza**;\n",
    "* Claude Shannon (1948) desenvolveu o conceito de Entropia em teoria da informação;\n",
    "* Para entender considere o sistema:\n",
    "\n",
    "![entropia 1](entropia1.png \"entropia 1\")\n",
    "\n",
    "> Considere que o sistema alterou seu comportamento\n",
    "\n",
    "![entropia 2](entropia2.png \"entropia 2\")\n",
    "\n",
    "* A equação para o seu cálculo: $E = -\\sum_{i} \\sum_{j}p_{ij}log_{2}p_{ij}$\n",
    "\n",
    "> Ela mede a energia total de um sistema considerando que o sistema está no estado $i$ e ocorre uma transição para o estado $j$. O $log_2$ é usado para quantificar a Entropia em termos de **bits**.\n",
    "\n",
    "* Assim, para imagem **entropia 1**:  $E = -(1log_2(1) + 1log_2(1)) = 0$\n",
    "* E para a imagem **entropia 2**: $E = -(1log_2(1) + 0.5log_2(0.5) + 0.5log_2(0.5)) = 0.693$\n",
    "> Após modificar seu comportamento, o sistema agregou maior nível de incerteza ou energia.\n",
    "\n",
    "#### Uso de Entropia no ID3\n",
    "\n",
    "* Considere uma coleção **S** de instâncias com exemplos positivos e negativos (duas classes distintas);\n",
    "* Nesse caso, assume-se a probabilidade de se pertencer a uma das duas classes (positiva ou negativa) de **S**;\n",
    "* Entropia nesse contexto é dada por:\n",
    "\n",
    "$E(S) = -p_\\oplus log_2 p_\\oplus - p_\\ominus log_2 p_\\ominus$\n",
    "* Para ilustrar, considere o conjunto **S** com 14 exemplos de algum conceito Booleano: 9 positivos e 5 negativos;\n",
    "* A entropia desse conjunto é dada por:\n",
    "\n",
    "$E(S) = -\\frac{9}{14}log_2\\frac{9}{14}-\\frac{5}{14}log_2\\frac{5}{14} = 0.94$\n",
    "\n",
    "* Em outros casos note:\n",
    "> para [7+, 7-]\n",
    "\n",
    "$E(S) = - \\frac{7}{14}log_2\\frac{7}{14}-\\frac{7}{14}log_2\\frac{7}{14} = 0.99 ... \\approx 1$\n",
    "\n",
    "> para [0+, 14-] ou [14+, 0-]\n",
    "\n",
    "$E(S) = - \\frac{14}{14}log_2\\frac{14}{14} = 0$\n",
    "\n",
    "* **Entropia mede o nível de certeza que temos sobre um evento**\n",
    "* Podemos generalizar para mais de dois possíveis valores ou classe:\n",
    "\n",
    "$E(S) = \\sum^{c}_{i=1}-p_ilog_2p_i$\n",
    "\n",
    "* Podemos estudar diferentes sistemas com Entropia, por exemplo séries temporais.\n",
    "* Por que o uso da função **log**?\n",
    "> Pois em teoria da informação mede-se a informação proveniente de uma fonte em bits. Esse conceito também permite pedir quantos bits são necessários para codificar uma mensagem (uma palavra por exemplo).\n",
    "\n",
    "#### Ganho de informação no ID3\n",
    "\n",
    "* Após definir **entropia**, podemos definir **ganho de informação**;\n",
    "* **Ganho de informação** mede a **efetividade** de um atributo em classificar um conjunto de treinamento. **Quão bom um atributo é** para classificar um conjunto de treinamento.\n",
    "* Ganho de informação de um atributo A: É a redução na Entropia, causada pelo particionamento de exemplos de acordo com este atributo.\n",
    "\n",
    "$\\mathbf{GI}(S, A) = E(S) - \\sum_{\\upsilon\\ \\in\\ \\mathbf{Valores}(A)} \\frac{S_\\upsilon}{S}E(S_\\upsilon)$\n",
    "\n",
    "> Em que o segundo termo mede a Entropia particionando o conjunto de treinamento de acordo com o atributo A.\n",
    "\n",
    "* Logo, **GI** mede a redução na Entropia ou na incerteza ao selecionar o atributo A\n",
    "\n",
    "* Por exemplo, considere **S** um conjunto de treinamento contendo o atributo Vento (Fraco ou Forte);\n",
    "> **S** contém 14 exemplos [9+, 5-]: 6 dos exemplos positivos e 2 exemplos dos negativos são definidos por Vento=Fraco (8 no total); 3 exemplos definidos por Vento=Forte tanto na classe positiva quanto negativa (6 no total).\n",
    "\n",
    ">  O ganho de informação ao selecionar o atributo Vento para a raíz de uma árvore de decisão é dado por:\n",
    "\n",
    "$S = [9+, 5-]$\n",
    "\n",
    "$S_{fraco} \\gets [6+, 2-]$\n",
    "\n",
    "$S_{forte} \\gets [3+, 3-]$\n",
    "\n",
    "$\\mathbf{GI}(S,A) = E(S) - \\sum_{\\upsilon\\ \\in\\ \\mathbf{Valores}(A)} \\frac{S_\\upsilon}{S}E(S_\\upsilon)$\n",
    "\n",
    "$\\mathbf{GI}(S,A) = 0.94 - \\frac{8}{14}E(S_{fraco}) - \\frac{6}{14}E(S_{forte})$\n",
    "\n",
    "$E(S_{fraco}) = -\\frac{6}{8}log_2\\frac{6}{8} - \\frac{2}{8}log_2\\frac{2}{8} = 0.811$\n",
    "\n",
    "$E(S_{fraco}) = -\\frac{3}{6}log_2\\frac{3}{6} - \\frac{3}{6}log_2\\frac{3}{6} = 1.0$\n",
    "\n",
    "$\\mathbf{GI}(S,A) = 0.94 - \\frac{8}{14}0.811 - \\frac{6}{14}1.00 = 0.048$\n",
    "\n",
    "* Essa medida de ganho de informação é utilizada pelo ID3 em cada passo da geração da árvore de decisão;\n",
    "> Nesse caso reduzimos muito pouco o nível de incerteza. Logo, esse atributo é bom para a raíz da árvore? **Não**.\n",
    "\n",
    "#### Exemplo - aprender a jogar tênis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dia</th>\n",
       "      <th>panorama</th>\n",
       "      <th>temperatura</th>\n",
       "      <th>umidade</th>\n",
       "      <th>vento</th>\n",
       "      <th>jogar_tenis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Ensolarado</td>\n",
       "      <td>Quente</td>\n",
       "      <td>Alta</td>\n",
       "      <td>Fraco</td>\n",
       "      <td>Não</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Ensolarado</td>\n",
       "      <td>Quente</td>\n",
       "      <td>Alta</td>\n",
       "      <td>Forte</td>\n",
       "      <td>Não</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>Nublado</td>\n",
       "      <td>Quente</td>\n",
       "      <td>Alta</td>\n",
       "      <td>Fraco</td>\n",
       "      <td>Sim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>Chuvoso</td>\n",
       "      <td>Intermediária</td>\n",
       "      <td>Alta</td>\n",
       "      <td>Fraco</td>\n",
       "      <td>Sim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>Chuvoso</td>\n",
       "      <td>Fria</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Fraco</td>\n",
       "      <td>Sim</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dia    panorama    temperatura umidade  vento jogar_tenis\n",
       "0   1  Ensolarado         Quente    Alta  Fraco         Não\n",
       "1   2  Ensolarado         Quente    Alta  Forte         Não\n",
       "2   3     Nublado         Quente    Alta  Fraco         Sim\n",
       "3   4     Chuvoso  Intermediária    Alta  Fraco         Sim\n",
       "4   5     Chuvoso           Fria  Normal  Fraco         Sim"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "exe = {\n",
    "    \"dia\": [\"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\", \"11\", \"12\", \"13\", \"14\"],\n",
    "    \"panorama\": [\"Ensolarado\", \"Ensolarado\", \"Nublado\", \"Chuvoso\", \"Chuvoso\", \"Chuvoso\", \"Nublado\", \"Ensolarado\", \"Ensolarado\", \"Chuvoso\", \"Ensolarado\", \"Nublado\", \"Nublado\", \"Chuvoso\"],\n",
    "    \"temperatura\": [\"Quente\", \"Quente\", \"Quente\", \"Intermediária\", \"Fria\", \"Fria\", \"Fria\", \"Intermediária\", \"Fria\", \"Intermediária\", \"Intermediária\", \"Intermediária\", \"Quente\", \"Intermediária\"],\n",
    "    \"umidade\": [\"Alta\", \"Alta\", \"Alta\", \"Alta\", \"Normal\", \"Normal\", \"Normal\", \"Alta\", \"Normal\", \"Normal\", \"Normal\", \"Alta\", \"Normal\", \"Alta\"],\n",
    "    \"vento\": [\"Fraco\", \"Forte\", \"Fraco\", \"Fraco\", \"Fraco\", \"Forte\", \"Forte\", \"Fraco\", \"Fraco\", \"Fraco\", \"Forte\", \"Forte\", \"Fraco\", \"Forte\"],\n",
    "    \"jogar_tenis\": [\"Não\", \"Não\", \"Sim\", \"Sim\", \"Sim\", \"Não\", \"Sim\", \"Não\", \"Sim\", \"Sim\", \"Sim\", \"Sim\", \"Sim\", \"Não\"]\n",
    "}\n",
    "exe_df = pd.DataFrame.from_dict(exe)\n",
    "exe_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Primeiro passo é calcular o ganho de informação para cada atributo:\n",
    "\n",
    "$\\mathbf{GI}(S, panorama) = 0.246$\n",
    "$\\mathbf{GI}(S, umidade) = 0.151$\n",
    "$\\mathbf{GI}(S, vento) = 0.048$\n",
    "$\\mathbf{GI}(S, temperatura) = 0.029$\n",
    "\n",
    "* O Atributo com maior ganho é selecionado para ser a raíz da árvore de decisão (panorama = 0.246)\n",
    "> É o que mais reduz o nível de incerteza. Criamos nós filhos a partir da raíz de acordo com os possíveis valores assumidos pelo atributo **panorama**\n",
    "\n",
    "* Agora que temos a raíz devemos proceder da mesmsa maneira para os demais ramos que surgem a partir da raíz. Em cada ramo consideramos somente os exemplos nele contigos, desde que haja divergência entre as classes de saída.\n",
    "\n",
    "![panorama](panorama.png \"Panorama_slide31\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
